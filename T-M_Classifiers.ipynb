{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![UKDS Logo](images/UKDS_Logos_Col_Grey_300dpi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Text-mining: Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the <a href=\"https://ukdataservice.ac.uk/\" target=_blank>UK Data Service</a> training series on *New Forms of Data for Social Science Research*. This series guides you through some of the most common and valuable new sources of data available for social science research: data collected from websites, social media platorms, text data, conducting simulations (agent based modelling), to name a few. We provide webinars, interactive notebooks containing live programming code, reading lists and more.\n",
    "\n",
    "* To access training materials for the entire series: <a href=\"https://github.com/UKDataServiceOpen/new-forms-of-data\" target=_blank>[Training Materials]</a>\n",
    "\n",
    "* To keep up to date with upcoming and past training events: <a href=\"https://ukdataservice.ac.uk/news-and-events/events\" target=_blank>[Events]</a>\n",
    "\n",
    "* To get in contact with feedback, ideas or to seek assistance: <a href=\"https://ukdataservice.ac.uk/help.aspx\" target=_blank>[Help]</a>\n",
    "\n",
    "<a href=\"https://www.research.manchester.ac.uk/portal/julia.kasmire.html\" target=_blank>Dr Julia Kasmire</a> and <a href=\"https://www.research.manchester.ac.uk/portal/diarmuid.mcdonnell.html\" target=_blank>Dr Diarmuid McDonnell</a> <br />\n",
    "UK Data Service  <br />\n",
    "University of Manchester <br />\n",
    "May 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Sentiment-Analysis-as-an-example-of-machine-learning/deep-learning-classification\" data-toc-modified-id=\"Sentiment-Analysis-as-an-example-of-machine-learning/deep-learning-classification-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Sentiment Analysis as an example of machine learning/deep learning classification</a></span></li><li><span><a href=\"#Analyse-trivial-documents-with-built-in-sentiment-analysis-tool\" data-toc-modified-id=\"Analyse-trivial-documents-with-built-in-sentiment-analysis-tool-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Analyse trivial documents with built-in sentiment analysis tool</a></span></li><li><span><a href=\"#Acquire-and-analyse-lell-trivial-documents\" data-toc-modified-id=\"Acquire-and-analyse-lell-trivial-documents-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Acquire and analyse lell trivial documents</a></span></li><li><span><a href=\"#Train-and-test-a-sentiment-analysis-tool-with-trivial-data\" data-toc-modified-id=\"Train-and-test-a-sentiment-analysis-tool-with-trivial-data-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Train and test a sentiment analysis tool with trivial data</a></span></li><li><span><a href=\"#You-can-train-and-test-a-sentiment-analysis-tool-with-more-interesting-data-too...\" data-toc-modified-id=\"You-can-train-and-test-a-sentiment-analysis-tool-with-more-interesting-data-too...-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>You can train and test a sentiment analysis tool with more interesting data too...</a></span></li><li><span><a href=\"#Conclusions\" data-toc-modified-id=\"Conclusions-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Conclusions</a></span></li><li><span><a href=\"#Further-reading\" data-toc-modified-id=\"Further-reading-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Further reading</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "There is a table of contents provided here at the top of the notebook, but you can also access this menu at any point by clicking the Table of Contents button on the top toolbar (an icon with four horizontal bars, if unsure hover your mouse over the buttons). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment analysis is a commonly used example of automatic classification. To be clear, automatic classification means that a model or learning algorithm has been trained on correctly classified documents and it uses this training to returns a probability assessment of what class a new document should belong to. \n",
    "\n",
    "Sentiment analysis works the same way, but usually only has two classes - positive and negative. A trained model looks at new data and says whether that new data is likely to be positive or negative. Let's take a look!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis as an example of machine learning/deep learning classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start off by importing and downloading some useful packages, including textblob. Textblob is based on nltk and has built in sentiment analysis tools. \n",
    "\n",
    "Run/Shift+Enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A files we can use is...  testing_set.csv\n",
      "A files we can use is...  training_set.csv\n",
      "\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\mzyssjkc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mzyssjkc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mzyssjkc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\mzyssjkc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\mzyssjkc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\mzyssjkc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os                         # os is a module for navigating your machine (e.g., file directories).\n",
    "import nltk                       # nltk stands for natural language tool kit and is useful for text-mining. \n",
    "import csv                        # csv is for importing and working with csv files\n",
    "import statistics\n",
    "\n",
    "\n",
    "# List all of the files in the \"data\" folder that is provided to you\n",
    "for file in os.listdir(\"./Sentiment_Analysis\"):\n",
    "   print(\"A files we can use is... \", file)\n",
    "print(\"\")\n",
    "\n",
    "!pip install -U textblob -q\n",
    "!python -m textblob.download_corpora -q\n",
    "from textblob import TextBlob "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse trivial documents with built-in sentiment analysis tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets get some data.\n",
    "\n",
    "Run/Shift+Enter, as above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "textblob.blob.TextBlob"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Doc1 = TextBlob(\"Textblob is just super. I love it!\")              # A few simple documents in textblog format\n",
    "Doc2 = TextBlob(\"Cabbages are the worst. Say no to cabbages!\")  \n",
    "Doc3 = TextBlob(\"Paris is the capital of France. \")   \n",
    "print(\"...\")\n",
    "type(Doc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docs 1 through 3 are Textblobs, which we can see by the output of type(Doc1). \n",
    "\n",
    "We get a Textblob by passing a string to the function that we imported above. Specifically, this is done by using this format --> Textblob('string goes here'). Textblobs are ready for analysis through the textblob tools, such as the built-in sentiment analysis tool that we see in the code below. \n",
    "\n",
    "Run/Shift+Enter on those Textblobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.47916666666666663, subjectivity=0.6333333333333333)\n",
      "Sentiment(polarity=-1.0, subjectivity=1.0)\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n"
     ]
    }
   ],
   "source": [
    "print(Doc1.sentiment)\n",
    "print(Doc2.sentiment)\n",
    "print(Doc3.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the previous code returns two values for each Textblob object. Polarity refers to a positive-negative spectrum while subjectivity refers to an opinion-fact spectrum. \n",
    "\n",
    "We can see, for example, that Doc1 is fairly positive but also quite subjective while Doc2 is very negative and very subjective. Doc3, in contrast, is both neutral and factual. \n",
    "\n",
    "Maybe you don't need both polarity and subjectivity. For example, if you are trying to categorise opinions, you don't need the subjectivity score and would only want the polarity. \n",
    "\n",
    "To get only one one of the two values, you can call the appropriate sub-function as shown below. \n",
    "\n",
    "Run/Shift+Enter for sub-functional fun. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47916666666666663\n",
      "0.6333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(Doc1.sentiment.polarity)\n",
    "print(Doc1.sentiment.subjectivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquire and analyse lell trivial documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Super. We have importand some documents (in our case, just sentences in string format) to textblob and analysed it using the built-in sentiment analyser. But we don't want to import documents one string at a time... That would take forever!\n",
    "\n",
    "Let's import data in .csv format instead! The data here comes from a set of customer reviews of amazon products. Naturally, not all of the comments in the product reviews are really on topic, but it does not actually matter for our purposes. But, I think it is only fair to warn you... There is some foul language and potentially objectionable personal opinions in the texts if you go through it all. \n",
    "\n",
    "Run/Shift+Enter (if you dare!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['@queenzita  then why do they have these stupid little pictures on my iPod I can add to text if no one can see them', '0'], ['at the Holocaust museum. here come the tears  love you guys so much!! miss you&lt;33', '0'], [\"just got done working out and now i'm sore \", '0'], ['i was under the impression that there was never rain in israel after Pesach. apparently i was wrong ', '0'], ['Lunchbreak is over, back to work ', '0'], ['@cramur They died  we are going to have them replaced before the big party.... are you going to be here for that!?!?', '0'], ['@ACUsports:  dang', '0'], [\"for someone frm Mumbai - it's spellbinding to see how organised the cities are. Marvelous society &amp; culture. Indians are light yrs away \", '0'], ['heart breaking ', '0'], ['@HairyGee You lost the url as the tweet was too long  Feel free to cut me out and resend to make it smaller. ;)', '0'], [\"I HATE when my alarm doesn't go off \", '0'], [\"@Kiki_Neko And thanks for also calling me a coward. I'll just add that to the list of insults you've used so far. ur hurtin my feelngs \", '0'], ['@MarshMash nor is it on mine ARGH!!! I dunno what happened ', '0'], ['@atraz oh damn that sucks  DUDE WHAAAAT!?!? whyyy? luckyy!', '0'], [\"I'm so sad.. Next week is a shit week because I have 8 exams, and I've just lost my agenda.  empty days..  I need something.. \", '0'], ['@yahyan are you serious babe? ', '0'], ['@tobycastle  i need a new helmet as well  maybe you can take my head to find one that fits..?', '0'], ['@mariapetersen just got back to sask from BC, so wont be making the 17 house drive for the party ', '0'], [\"@ambiguousaccent oh  whatever shit it is, I hope it will pass quickly. I'll be waiting for your result in getting me a Followill.\", '0'], ['And the clouds come rolling in. ', '0']]\n"
     ]
    }
   ],
   "source": [
    "with open('./Sentiment_Analysis/training_set.csv', newline='') as f:              # 2, a csv of scored product reviews\n",
    "    reader = csv.reader(f)\n",
    "    Doc_set = list(reader)\n",
    "\n",
    "print(Doc_set[:20])                                                          # 3, a quick look at the first 10 items in the csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very good start (although you will see what I mean about the off-topic comments and foul language). \n",
    "\n",
    "Now, the csv has multiple strings per row, but we need to pass that to texblob to create a Textblob object before we can get a polirity or sujectivity score. \n",
    "\n",
    "The code below creates a new list that has the text string and the sentiment score for each item in the imported Doc_set, and also shows you the first 20 results of that new list to look at. \n",
    "\n",
    "Run/Shift+Enter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['@queenzita  then why do they have these stupid little pictures on my iPod I can add to text if no one can see them', Sentiment(polarity=-0.49374999999999997, subjectivity=0.75)], ['at the Holocaust museum. here come the tears  love you guys so much!! miss you&lt;33', Sentiment(polarity=0.40625, subjectivity=0.4)], [\"just got done working out and now i'm sore \", Sentiment(polarity=0.0, subjectivity=0.0)], ['i was under the impression that there was never rain in israel after Pesach. apparently i was wrong ', Sentiment(polarity=-0.225, subjectivity=0.625)], ['Lunchbreak is over, back to work ', Sentiment(polarity=0.0, subjectivity=0.0)], ['@cramur They died  we are going to have them replaced before the big party.... are you going to be here for that!?!?', Sentiment(polarity=0.0, subjectivity=0.1)], ['@ACUsports:  dang', Sentiment(polarity=0.0, subjectivity=0.0)], [\"for someone frm Mumbai - it's spellbinding to see how organised the cities are. Marvelous society &amp; culture. Indians are light yrs away \", Sentiment(polarity=0.7, subjectivity=0.85)], ['heart breaking ', Sentiment(polarity=0.0, subjectivity=0.0)], ['@HairyGee You lost the url as the tweet was too long  Feel free to cut me out and resend to make it smaller. ;)', Sentiment(polarity=0.15000000000000002, subjectivity=0.675)], [\"I HATE when my alarm doesn't go off \", Sentiment(polarity=-0.8, subjectivity=0.9)], [\"@Kiki_Neko And thanks for also calling me a coward. I'll just add that to the list of insults you've used so far. ur hurtin my feelngs \", Sentiment(polarity=0.15000000000000002, subjectivity=0.6)], ['@MarshMash nor is it on mine ARGH!!! I dunno what happened ', Sentiment(polarity=0.0, subjectivity=0.0)], ['@atraz oh damn that sucks  DUDE WHAAAAT!?!? whyyy? luckyy!', Sentiment(polarity=-0.5859375, subjectivity=0.3)], [\"I'm so sad.. Next week is a shit week because I have 8 exams, and I've just lost my agenda.  empty days..  I need something.. \", Sentiment(polarity=-0.19999999999999998, subjectivity=0.575)], ['@yahyan are you serious babe? ', Sentiment(polarity=-0.3333333333333333, subjectivity=0.6666666666666666)], ['@tobycastle  i need a new helmet as well  maybe you can take my head to find one that fits..?', Sentiment(polarity=0.13636363636363635, subjectivity=0.45454545454545453)], ['@mariapetersen just got back to sask from BC, so wont be making the 17 house drive for the party ', Sentiment(polarity=0.0, subjectivity=0.0)], [\"@ambiguousaccent oh  whatever shit it is, I hope it will pass quickly. I'll be waiting for your result in getting me a Followill.\", Sentiment(polarity=0.06666666666666665, subjectivity=0.65)], ['And the clouds come rolling in. ', Sentiment(polarity=0.0, subjectivity=0.0)]]\n"
     ]
    }
   ],
   "source": [
    "Doc_set_analysed = []\n",
    "\n",
    "for item in Doc_set:\n",
    "    Doc_set_analysed.append([item[0], TextBlob(item[0]).sentiment])\n",
    "\n",
    "print(Doc_set_analysed[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, try to edit the code above to return only the polarity or only the subjectivity. \n",
    "\n",
    "While you are at it, try to edit the code to return a different number of results to look at. How about 25?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test a sentiment analysis tool with trivial data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The built-in tool is all well and good, but... have a look back at the sentiment analysis scores for Doc1 and Doc2. \n",
    "- Doc1 scored as .48 on polarity, about halfway between totally neutral and totally positive. \n",
    "- Doc2 scored -1 on polarity, which is the most negative it could score. \n",
    "\n",
    "Do we really think Doc2 is so much more negative than Doc1 is positive? Hmmmm. Maybe the built-in sentiment analyser is not as accurate as we would want. Let's try to train our own, starting with a small set of trivial training and testing data sets. \n",
    "\n",
    "The following code does a few different things:\n",
    "- It defines 'train' as a data set with 10 sentences, each of which is marked as 'pos' or 'neg'.\n",
    "- It defines 'test' as a data set with 6 completely different sentences, also marked as 'pos' or 'neg'. \n",
    "- It imports NaiveBayesClassifier from the textblob.classifiers.\n",
    "- It defines 'cl' as a brand new NaiveBayesClassifier that is trained on the 'train' data set. \n",
    "\n",
    "Run/Shift+Enter to make it so. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [\n",
    "    ('I love this sandwich.', 'pos'),\n",
    "    ('this is an amazing place!', 'pos'),\n",
    "    ('I feel very good about these beers.', 'pos'),\n",
    "    ('this is my best work.', 'pos'),\n",
    "    (\"what an awesome view\", 'pos'),\n",
    "    ('I do not like this restaurant', 'neg'),\n",
    "    ('I am tired of this stuff.', 'neg'),\n",
    "    (\"I can't deal with this\", 'neg'),\n",
    "    ('he is my sworn enemy!', 'neg'),\n",
    "    ('my boss is horrible.', 'neg')]\n",
    "test = [\n",
    "     ('the beer was good.', 'pos'),\n",
    "     ('I do not enjoy my job', 'neg'),\n",
    "     (\"I ain't feeling dandy today.\", 'neg'),\n",
    "     (\"I feel amazing!\", 'pos'),\n",
    "     ('Gary is a friend of mine.', 'pos'),\n",
    "     (\"I can't believe I'm doing this.\", 'neg')]\n",
    "\n",
    "\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "cl = NaiveBayesClassifier(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm. The code ran but there is nothing to see. This is because we have no output! Let's get some output and see what it did. \n",
    "\n",
    "The next code block plays around with 'cl', the classifier we trained on our 'train' data set.\n",
    "\n",
    "The first line asks 'cl' to return a judgment of one sentence about a library. \n",
    "\n",
    "Then, we ask it to return a judgement of another sentence about something being a doozy. Although both times we get a judgement on whether the sentence is 'pos' or 'neg', the second one has more detailed sub-judgements we can analyse that show us how the positive and negative the sentence is so we can see whether the overall judgement is close or not. \n",
    "\n",
    "Do the Run/Shift+Enter thing that you are so good at doing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our 'cl' classifier says 'This is an amazing library!' is  pos\n",
      "...\n",
      "Our 'cl' classifier says 'This one is a doozy.' is probably pos because its positive score is  0.63  and its negative score is  0.37 .\n"
     ]
    }
   ],
   "source": [
    "print(\"Our 'cl' classifier says 'This is an amazing library!' is \", cl.classify(\"This is an amazing library!\"))\n",
    "print('...')\n",
    "\n",
    "prob_dist = cl.prob_classify(\"This one is a doozy.\")\n",
    "print(\"Our 'cl' classifier says 'This one is a doozy.' is probably\",\n",
    "      prob_dist.max(), \"because its positive score is \",\n",
    "      round(prob_dist.prob(\"pos\"), 2),\n",
    "      \" and its negative score is \",\n",
    "      round(prob_dist.prob(\"neg\"), 2),\n",
    "      \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Super. Now... What if we want to apply our 'cl' classifier to a document with multiple sentences... What kind of judgements can we get with that? \n",
    "\n",
    "Well, textblob is sophisticated enough to give an overall 'pos' or 'neg' judgement, as well as a sentence-by-sentence judgement. \n",
    "\n",
    "Run/Shift+Enter, buddy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall, 'blob' is  pos  because it's sentences are ...\n",
      "The beer is good.\n",
      "pos\n",
      "But the hangover is horrible.\n",
      "neg\n"
     ]
    }
   ],
   "source": [
    "blob = TextBlob(\"The beer is good. But the hangover is horrible.\", classifier=cl)\n",
    "\n",
    "print(\"Overall, 'blob' is \", blob.classify(), \" because it's sentences are ...\")\n",
    "for s in blob.sentences:\n",
    "     print(s)\n",
    "     print(s.classify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we try to classify a document that we converted to Textblob format with the built-in sentiment analyser?\n",
    "\n",
    "Well, we still have Doc1 to try it on.\n",
    "\n",
    "Run/Shift+Enter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Textblob is just super. I love it!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "This blob has no classifier. Train one first!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-e29ad803911a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDoc1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mDoc1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\textblob\\blob.py\u001b[0m in \u001b[0;36mclassify\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    418\u001b[0m         \u001b[1;34m\"\"\"Classify the blob using the blob's ``classifier``.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mNameError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"This blob has no classifier. Train one first!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: This blob has no classifier. Train one first!"
     ]
    }
   ],
   "source": [
    "print(Doc1)\n",
    "Doc1.classify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh huh. We get an error. \n",
    "\n",
    "The error message says the blob known as Doc1 has no classifier. It suggests we train one first, but we can just apply 'cl'. \n",
    "\n",
    "Run/Shift+Enter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_Doc1 = TextBlob('Textblob is just super. I love it!', classifier=cl)\n",
    "cl_Doc1.classify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, when we classify the string that originally went into Doc1 using our 'cl' classifier, we still get a positive judgement. \n",
    "\n",
    "Now, what about accuracy? We have been using 'cl' even though it is trained on a REALLY tiny training data set. What does that do to our accuracy? For that, we need to run an accuracy challenge using our test data set. \n",
    "\n",
    "Run/Shift+Enter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.accuracy(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm. Not perfect.\n",
    "\n",
    "Fortunately, we can add more training data and try again. The code below defines a new training data set and then runs a re-training functiong called 'update' on our 'cl' classifier. \n",
    "\n",
    "Run/Shift+Enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = [('She is my best friend.', 'pos'),\n",
    "            (\"I'm happy to have a new friend.\", 'pos'),\n",
    "            (\"Stay thirsty, my friend.\", 'pos'),\n",
    "            (\"He ain't from around here.\", 'neg')]\n",
    "\n",
    "cl.update(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, edit and run the next code block to test out how the new_data has improved 'cl. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy and paste the accuracy challenge from above into this cell and re-run it to get an updated accuracy score. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You can train and test a sentiment analysis tool with more interesting data too..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all well and good, but seriously, 'cl' is trained on some seriously trivial data. What if we want to use some more interesting data, like the Doc_set that we imported from .csv earlier?\n",
    "\n",
    "Well, we are in luck! Sort of...\n",
    "\n",
    "We can definitely train a classifier on Doc_set, but let's just have a closer look at Doc_set before we jump right in and try that. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Doc_set[:10])\n",
    "print('...')\n",
    "print(len(Doc_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doc_set is a set of comments that come from product reviews. Each item has two strings, the first of which is the comment and the second of which is string with a number 4, 2 or 0. This second item, the string with a number inside, as a score of whether the comment is positive or negative. These scores may have been manually created, or may be the result of a semi-manual or supervised automation process. Excellent for our purposes, but not ideal because:\n",
    "- These scores are strings rather than integers. You can tell because they are enclose in quotes.\n",
    "- These scores range from 0 (negative) to 4 (positive) and also contains 2 (neutral), while the textblob sentiment analysis and classifier functions we have been using return scores from -1 (negative) through 0 (neutral) to 1 (positive). \n",
    "\n",
    "Well, we could change all the 4 to 1, 2 to 0 and 0 to -1 with RegEx if we wanted. But as you will see, this is not strictly necessary. \n",
    "\n",
    "However, there is another issue. Doc_set has 20,000 items. This is big, but this is actually MUCH smaller than it could be. This is a subset of a 1,000,000+ item data set that you can download for free (see extra resources and reading at the end). The original data set was way too big for jupyter notebook and was even too big for me to analyse on my laptop. I know because I tried. When you find yourself in a situation like this, you can try: \n",
    "- Accessing proper research computing facilities (good for real research, too much for a code demo). \n",
    "- Dividing a too big data set into into chunks, and train/update a chunk at a time. \n",
    "- Processing a too big data set to remove punctuation, stop words, urls, twitter handles, etc. (saving computer power for what matters).\n",
    "- Or a combination of these options. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can train a classifier on whatever data you want and with whatever categories you want. \n",
    "\n",
    "Want to train a classifier to recognise sarcasm? Go for it. \n",
    "How about recognising lies in political speeches? Good idea. \n",
    "How about tweets from bots or from real people? Definitely useful. \n",
    "\n",
    "The hard part is actually getting the data ready to feed to train your classifier. But feel feel to start small. 10 items? 100? what can you do quickly that will give you enough of an idea to see if it is worth investing more time. \n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Books, tutorials, package recommendations, etc. for Python\n",
    "\n",
    "- Natural Language Processing with Python by Steven Bird, Ewan Klein and Edward Loper, http://www.nltk.org/book/\n",
    "- Foundations of Statistical Natural Language Processing by Christopher Manning and Hinrich Schütze, https://nlp.stanford.edu/fsnlp/promo/\n",
    "- Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics and Speech Recognition by Dan Jurafsky and James H. Martin, https://web.stanford.edu/~jurafsky/slp3/ed3book.pdf\n",
    "- Deep Learning in Natural Language Processing by Li Deng, Yang Liu, https://lidengsite.wordpress.com/book-chapters/\n",
    "- Sentiment Analysis data sets https://blog.cambridgespark.com/50-free-machine-learning-datasets-sentiment-analysis-b9388f79c124\n",
    "\n",
    "NLTK options\n",
    "- nltk.corpus http://www.nltk.org/howto/corpus.html\n",
    "- Data Camp tutorial on sentiment analysis with nltk https://www.datacamp.com/community/tutorials/simplifying-sentiment-analysis-python\n",
    "- Vader sentiment analysis script available on github (nltk) https://www.nltk.org/_modules/nltk/sentiment/vader.html\n",
    "- TextBlob https://textblob.readthedocs.io/en/dev/\n",
    "- Flair, a NLP script available on github https://github.com/flairNLP/flair\n",
    "\n",
    "spaCy options\n",
    "- spaCy https://nlpforhackers.io/complete-guide-to-spacy/\n",
    "- Data Quest tutorial on sentiment analysis with spaCy https://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/\n",
    "\n",
    "\n",
    "Books and package recommendations for R\n",
    "- Quanteda, an R package for text analysis https://quanteda.io/​\n",
    "- Text Mining with R, a free online book https://www.tidytextmining.com/​"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
